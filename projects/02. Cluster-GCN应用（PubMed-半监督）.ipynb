{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Cluster-GCN应用（PubMed-半监督）\n",
    "\n",
    "## 1. 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "\n",
    "dataset = Planetoid(root='./dataset', name='PubMed', transform=NormalizeFeatures())\n",
    "\n",
    "print(f'数据集：{dataset}')\n",
    "print(f'图数量：{len(dataset)}')\n",
    "print(f'节点特征数量：{dataset.num_features}')\n",
    "print(f'节点标签数量：{dataset.num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取第一个图对象\n",
    "data = dataset[0]\n",
    "print(f'图对象：{data}')\n",
    "\n",
    "# 获取这张图的统计信息\n",
    "print(f'节点数量：{data.num_nodes}')\n",
    "print(f'边数量：{data.num_edges}')\n",
    "print(f'节点平均度数：{data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'训练节点率：{int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
    "print(f'是否存在孤立结点：{data.has_isolated_nodes()}')\n",
    "print(f'是否自环图：{data.has_self_loops()}')\n",
    "print(f'是否无向图：{data.is_undirected()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'训练集节点数：{data.train_mask.sum()}')\n",
    "print(f'验证集节点数：{data.val_mask.sum()}')\n",
    "print(f'测试集节点数：{data.test_mask.sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 统计每个类别的数量\n",
    "unique_labels, counts = torch.unique(data.y, return_counts=True)\n",
    "\n",
    "# 打印每个类别的数量\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f'类别 {label.item()}: {count.item()} 个样本')\n",
    "\n",
    "# 绘制每个类别的数量\n",
    "plt.bar(unique_labels.numpy(), counts.numpy())\n",
    "plt.xlabel('labels')\n",
    "plt.ylabel('counts')\n",
    "plt.title('labels distribution')\n",
    "\n",
    "# 在每个条形图上添加数字标签\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    plt.text(label.item(), count.item(), str(count.item()), ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networkx 可视化\n",
    "# import networkx as nx\n",
    "# from torch_geometric.utils import to_networkx\n",
    "\n",
    "# # 创建无向图\n",
    "# G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "# pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# # 创建图对象\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "# # 可视化\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=30, node_color=data.y, cmap='Set2')\n",
    "# plt.title('PubMed Dataset Visualization')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Full-batch 加载训练\n",
    "\n",
    "### 2.1 采用GCN算子构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用GCN算子设计模型\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, out_channels=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 128)\n",
    "        self.conv2 = GCNConv(128, 32)\n",
    "        self.conv3 = GCNConv(32, out_channels)\n",
    "        \n",
    "        self.dp = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "gcn_model = GCN(out_channels=dataset.num_classes)\n",
    "print(gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(gcn_model, input_data=(data.x, data.edge_index), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和评估\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gcn_model = gcn_model.to(device)\n",
    "optimizer = optim.Adam(gcn_model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "data = data.to(device)\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    preds = out.argmax(dim=1)\n",
    "    \n",
    "    \n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        correct = preds[mask] == data.y[mask]\n",
    "        accs.append(int(correct.sum()) / int(mask.sum()))\n",
    "    return accs\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1000):\n",
    "    loss = train(gcn_model)\n",
    "    train_acc, val_acc, test_acc = test(gcn_model)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/1000, Loss: {loss:.4f} Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "torch.save(gcn_model, os.path.join('weights', 'gcn_pubmed_model.pth'))\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'训练时间：{end_time - start_time:.2f}秒')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 采用Cluster-GCN算子构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ClusterGCNConv\n",
    "\n",
    "class ClusterGCN(nn.Module):\n",
    "    def __init__(self, out_channels=3):\n",
    "        super(ClusterGCN, self).__init__()\n",
    "        self.conv1 = ClusterGCNConv(dataset.num_features, 128)\n",
    "        self.conv2 = ClusterGCNConv(128, 32)\n",
    "        self.conv3 = ClusterGCNConv(32, out_channels)\n",
    "        \n",
    "        self.dp = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "cluster_gcn_model = ClusterGCN(out_channels=dataset.num_classes)\n",
    "print(cluster_gcn_model)\n",
    "\n",
    "summary(cluster_gcn_model, input_data=(data.x, data.edge_index), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 训练和评估\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cluster_gcn_model = cluster_gcn_model.to(device)\n",
    "optimizer = optim.Adam(cluster_gcn_model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "data = data.to(device)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1000):\n",
    "    loss = train(cluster_gcn_model)\n",
    "    train_acc, val_acc, test_acc = test(cluster_gcn_model)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/1000, Loss: {loss:.4f} Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "torch.save(cluster_gcn_model, os.path.join('weights', 'cluster_gcn_pubmed_model.pth'))\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'训练时间：{end_time - start_time:.2f}秒')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ClusterLoader 加载训练\n",
    "\n",
    "### 3.1 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import ClusterLoader, ClusterData\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "data = data.cpu()\n",
    "\n",
    "# 创建子图\n",
    "cluster_data = ClusterData(data, num_parts=128)\n",
    "\n",
    "# 创建ClusterLoader 随机分区\n",
    "train_loader = ClusterLoader(cluster_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "total_num_nodes = 0\n",
    "\n",
    "for step, sub_data in enumerate(train_loader):\n",
    "   print(f'Step: {step + 1}')\n",
    "   print('='*20)\n",
    "   print(f'Number of nodes in the current batch: {sub_data.num_nodes}')\n",
    "   print(sub_data)\n",
    "   print()\n",
    "   total_num_nodes += sub_data.num_nodes\n",
    "   \n",
    "print(f'Iterated over {total_num_nodes}  of {data.num_nodes} nodes！')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_gnn_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
